{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8YJcPWLOFOj"
   },
   "source": [
    "### `LSTM.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: music21 in ./.local/lib/python3.11/site-packages (9.1.0)\n",
      "Requirement already satisfied: chardet in ./.local/lib/python3.11/site-packages (from music21) (5.2.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from music21) (1.3.2)\n",
      "Requirement already satisfied: jsonpickle in ./.local/lib/python3.11/site-packages (from music21) (3.0.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (from music21) (3.8.2)\n",
      "Requirement already satisfied: more-itertools in ./.local/lib/python3.11/site-packages (from music21) (10.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from music21) (1.26.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from music21) (2.31.0)\n",
      "Requirement already satisfied: webcolors>=1.5 in /opt/conda/lib/python3.11/site-packages (from music21) (1.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->music21) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib->music21) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->music21) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->music21) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->music21) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib->music21) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->music21) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib->music21) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->music21) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->music21) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->music21) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->music21) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->music21) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F0JemjEeN5ZO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 23:07:00.252145: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-08 23:07:01.007067: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-08 23:07:01.007137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-08 23:07:01.137388: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-08 23:07:01.394664: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "import keras.utils\n",
    "from music21 import converter, instrument, note, chord\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFcX_sgIPbms",
    "outputId": "d7db2bae-ea27-4246-fbb1-f49794c2d6f0"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')\n",
    "train_files = glob.glob('maestro_v3_2013/*.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UN8drrgBODQn"
   },
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes = get_notes()\n",
    "    # notes = pickle.load('/content/drive/My Drive/Colab Notebooks/final_project_neuro240_files/data/notes')\n",
    "\n",
    "    # get amount of pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    model = create_network(network_input, n_vocab)\n",
    "\n",
    "    train(model, network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1tsJJJEtOKtq"
   },
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in train_files:\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse()\n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    try:\n",
    "        with open('/data/notes', 'wb') as filepath:\n",
    "            pickle.dump(notes, filepath)\n",
    "        print(\"Notes saved\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rXARdAY4ONDP"
   },
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = keras.utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gAs4dAPhOQMU"
   },
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Yawf61mHOSeV"
   },
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(network_input, network_output, epochs=200, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bxx-k1Y7OUCv",
    "outputId": "84a1a3f5-34e1-4c37-96e3-975a95ba9c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_12_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_19_R2_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_02_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_17_R3_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_07_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_08_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_17_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_06_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_15_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_07_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_16_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_18_R3_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_14_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_03_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_03_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_07_R3_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_15_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_11_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_13_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_04_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_08_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_02_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_10_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_11_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_05_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_02_R1_2013_wav--5.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_08_R2_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_09_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_17_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_19_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_18_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_18_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_03_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_12_R3_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_14_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_11_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_10_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_04_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_09_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_08_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_19_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_14_R2_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_15_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_17_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_08_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_15_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_06_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--5.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_12_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_14_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_17_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_05_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_13_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_11_R2_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_07_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_08_R3_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_02_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_18_R2_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_11_R3_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_10_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_11_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_02_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_03_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_12_R3_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_18_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_18_R3_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_16_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_17_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_15_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_08_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_07_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_15_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_09_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_05_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_04_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_08_R3_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_02_R2_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_13_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_04_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_03_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_12_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_14_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_15_R3_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_07_R3_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_06_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_18_R1_2013_wav--5.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_19_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_17_R2_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_02_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_04_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_13_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_02_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_10_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_11_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_12_R3_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_07_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_03_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_14_R3_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_18_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_19_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_08_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_09_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_08_R1_2013_wav--5.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_17_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_07_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_16_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_02_R2_2013_wav--5.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_04_R2_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_18_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_06_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_15_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_14_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_17_R3_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_08_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_14_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_12_R2_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_18_R2_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_11_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_19_R2_2013_wav--3.midi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 14:56:17.109496: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 14:56:17.119119: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-03 14:56:17.121975: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-03 14:56:17.125520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-03 14:56:17.128425: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-03 14:56:17.131141: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-03 14:56:17.327449: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-03 14:56:17.329266: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-03 14:56:17.330960: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-03 14:56:17.332632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n",
      "2024-04-03 14:56:17.774472: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 14:56:30.812827: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "2024-04-03 14:56:31.458923: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fd7346f8840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-03 14:56:31.458966: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-04-03 14:56:31.464359: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712156191.549492    1712 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2206/2206 [==============================] - ETA: 0s - loss: 5.6572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2206/2206 [==============================] - 896s 402ms/step - loss: 5.6572\n",
      "Epoch 2/200\n",
      "2206/2206 [==============================] - 888s 402ms/step - loss: 5.4377\n",
      "Epoch 3/200\n",
      "2206/2206 [==============================] - 888s 402ms/step - loss: 5.4083\n",
      "Epoch 4/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 5.3657\n",
      "Epoch 5/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 5.3248\n",
      "Epoch 6/200\n",
      "2206/2206 [==============================] - 885s 401ms/step - loss: 5.2949\n",
      "Epoch 7/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 5.2712\n",
      "Epoch 8/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 5.2403\n",
      "Epoch 9/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 5.2092\n",
      "Epoch 10/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 5.1767\n",
      "Epoch 11/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 5.1465\n",
      "Epoch 12/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 5.1145\n",
      "Epoch 13/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 5.0794\n",
      "Epoch 14/200\n",
      "2206/2206 [==============================] - 888s 403ms/step - loss: 5.0460\n",
      "Epoch 15/200\n",
      "2206/2206 [==============================] - 888s 402ms/step - loss: 5.0070\n",
      "Epoch 16/200\n",
      "2206/2206 [==============================] - 888s 402ms/step - loss: 4.9716\n",
      "Epoch 17/200\n",
      "2206/2206 [==============================] - 888s 403ms/step - loss: 4.9363\n",
      "Epoch 18/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 4.9002\n",
      "Epoch 19/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 4.8648\n",
      "Epoch 20/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 4.8316\n",
      "Epoch 21/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 4.7948\n",
      "Epoch 22/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 4.7629\n",
      "Epoch 23/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 4.7324\n",
      "Epoch 24/200\n",
      "2206/2206 [==============================] - 892s 404ms/step - loss: 4.7001\n",
      "Epoch 25/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.6686\n",
      "Epoch 26/200\n",
      "2206/2206 [==============================] - 892s 404ms/step - loss: 4.6375\n",
      "Epoch 27/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.6052\n",
      "Epoch 28/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.5732\n",
      "Epoch 29/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 4.5483\n",
      "Epoch 30/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.5225\n",
      "Epoch 31/200\n",
      "2206/2206 [==============================] - 892s 405ms/step - loss: 4.4948\n",
      "Epoch 32/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.4661\n",
      "Epoch 33/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.4390\n",
      "Epoch 34/200\n",
      "2206/2206 [==============================] - 892s 404ms/step - loss: 4.4164\n",
      "Epoch 35/200\n",
      "2206/2206 [==============================] - 892s 404ms/step - loss: 4.3920\n",
      "Epoch 36/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 4.3633\n",
      "Epoch 37/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.3442\n",
      "Epoch 38/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 4.3193\n",
      "Epoch 39/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.2972\n",
      "Epoch 40/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 4.2720\n",
      "Epoch 41/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.2592\n",
      "Epoch 42/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.2282\n",
      "Epoch 43/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 4.2063\n",
      "Epoch 44/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 4.1859\n",
      "Epoch 45/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 4.1638\n",
      "Epoch 46/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.1466\n",
      "Epoch 47/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.1190\n",
      "Epoch 48/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 4.0926\n",
      "Epoch 49/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 4.0722\n",
      "Epoch 50/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 4.0578\n",
      "Epoch 51/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 4.0424\n",
      "Epoch 52/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 4.0256\n",
      "Epoch 53/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 4.0041\n",
      "Epoch 54/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.9898\n",
      "Epoch 55/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.9706\n",
      "Epoch 56/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.9413\n",
      "Epoch 57/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.9243\n",
      "Epoch 58/200\n",
      "2206/2206 [==============================] - 888s 403ms/step - loss: 3.9077\n",
      "Epoch 59/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.8939\n",
      "Epoch 60/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.9603\n",
      "Epoch 61/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 3.8737\n",
      "Epoch 62/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 3.8474\n",
      "Epoch 63/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 4.1590\n",
      "Epoch 64/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 4.2633\n",
      "Epoch 65/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 4.1032\n",
      "Epoch 66/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 3.9779\n",
      "Epoch 67/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 3.9407\n",
      "Epoch 68/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.8664\n",
      "Epoch 69/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.8405\n",
      "Epoch 70/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 3.8182\n",
      "Epoch 71/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 3.8141\n",
      "Epoch 72/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 3.8461\n",
      "Epoch 73/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 3.8862\n",
      "Epoch 74/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.8338\n",
      "Epoch 75/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.8397\n",
      "Epoch 76/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.7972\n",
      "Epoch 77/200\n",
      "2206/2206 [==============================] - 888s 403ms/step - loss: 3.7647\n",
      "Epoch 78/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 3.7411\n",
      "Epoch 79/200\n",
      "2206/2206 [==============================] - 886s 401ms/step - loss: 3.7164\n",
      "Epoch 80/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 3.7049\n",
      "Epoch 81/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 3.6887\n",
      "Epoch 82/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 3.6877\n",
      "Epoch 83/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 3.7144\n",
      "Epoch 84/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 3.7366\n",
      "Epoch 85/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 3.6758\n",
      "Epoch 86/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 3.6670\n",
      "Epoch 87/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 3.6917\n",
      "Epoch 88/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 3.6711\n",
      "Epoch 89/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.6518\n",
      "Epoch 90/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 3.6120\n",
      "Epoch 91/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.6016\n",
      "Epoch 92/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 3.5873\n",
      "Epoch 93/200\n",
      "2206/2206 [==============================] - 897s 407ms/step - loss: 3.5776\n",
      "Epoch 94/200\n",
      "2206/2206 [==============================] - 893s 405ms/step - loss: 3.5554\n",
      "Epoch 95/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 3.5486\n",
      "Epoch 96/200\n",
      "2206/2206 [==============================] - 885s 401ms/step - loss: 3.5451\n",
      "Epoch 97/200\n",
      "2206/2206 [==============================] - 883s 400ms/step - loss: 3.6801\n",
      "Epoch 98/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 3.5907\n",
      "Epoch 99/200\n",
      "2206/2206 [==============================] - 897s 407ms/step - loss: 3.5414\n",
      "Epoch 100/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.5206\n",
      "Epoch 101/200\n",
      "2206/2206 [==============================] - 883s 400ms/step - loss: 3.5000\n",
      "Epoch 102/200\n",
      "2206/2206 [==============================] - 883s 400ms/step - loss: 3.4977\n",
      "Epoch 103/200\n",
      "2206/2206 [==============================] - 884s 401ms/step - loss: 3.4876\n",
      "Epoch 104/200\n",
      "2206/2206 [==============================] - 884s 401ms/step - loss: 3.4641\n",
      "Epoch 105/200\n",
      "2206/2206 [==============================] - 883s 400ms/step - loss: 3.4454\n",
      "Epoch 106/200\n",
      "2206/2206 [==============================] - 884s 401ms/step - loss: 3.4333\n",
      "Epoch 107/200\n",
      "2206/2206 [==============================] - 884s 401ms/step - loss: 3.4245\n",
      "Epoch 108/200\n",
      "2206/2206 [==============================] - 885s 401ms/step - loss: 3.4174\n",
      "Epoch 109/200\n",
      "2206/2206 [==============================] - 884s 401ms/step - loss: 3.3954\n",
      "Epoch 110/200\n",
      "2206/2206 [==============================] - 884s 401ms/step - loss: 3.3795\n",
      "Epoch 111/200\n",
      "2206/2206 [==============================] - 884s 401ms/step - loss: 3.3657\n",
      "Epoch 112/200\n",
      "2206/2206 [==============================] - 883s 400ms/step - loss: 3.3577\n",
      "Epoch 113/200\n",
      "2206/2206 [==============================] - 884s 401ms/step - loss: 3.3420\n",
      "Epoch 114/200\n",
      "2206/2206 [==============================] - 883s 400ms/step - loss: 3.3304\n",
      "Epoch 115/200\n",
      "2206/2206 [==============================] - 885s 401ms/step - loss: 3.3232\n",
      "Epoch 116/200\n",
      "2206/2206 [==============================] - 883s 400ms/step - loss: 3.3163\n",
      "Epoch 117/200\n",
      "2206/2206 [==============================] - 882s 400ms/step - loss: 3.3986\n",
      "Epoch 118/200\n",
      "2206/2206 [==============================] - 882s 400ms/step - loss: 3.3229\n",
      "Epoch 119/200\n",
      "2206/2206 [==============================] - 882s 400ms/step - loss: 3.3333\n",
      "Epoch 120/200\n",
      "2206/2206 [==============================] - 882s 400ms/step - loss: 3.3100\n",
      "Epoch 121/200\n",
      "2206/2206 [==============================] - 881s 399ms/step - loss: 3.8450\n",
      "Epoch 122/200\n",
      " 155/2206 [=>............................] - ETA: 13:38 - loss: 3.3153"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2206/2206 [==============================] - 882s 400ms/step - loss: 3.2719\n",
      "Epoch 125/200\n",
      "2206/2206 [==============================] - 884s 401ms/step - loss: 3.2443\n",
      "Epoch 127/200\n",
      "2206/2206 [==============================] - 883s 400ms/step - loss: 3.2709\n",
      "Epoch 128/200\n",
      "2206/2206 [==============================] - 883s 400ms/step - loss: 3.2328\n",
      "Epoch 129/200\n",
      "2206/2206 [==============================] - 883s 400ms/step - loss: 3.2161\n",
      "Epoch 130/200\n",
      "2206/2206 [==============================] - 884s 401ms/step - loss: 3.2418\n",
      "Epoch 131/200\n",
      "2206/2206 [==============================] - 884s 401ms/step - loss: 3.2222\n",
      "Epoch 132/200\n",
      "2206/2206 [==============================] - 883s 400ms/step - loss: 3.1874\n",
      "Epoch 133/200\n",
      "2206/2206 [==============================] - 884s 401ms/step - loss: 3.1765\n",
      "Epoch 134/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 3.1672\n",
      "Epoch 135/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.1600\n",
      "Epoch 136/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.1503\n",
      "Epoch 137/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.1359\n",
      "Epoch 138/200\n",
      "2206/2206 [==============================] - 888s 403ms/step - loss: 3.1253\n",
      "Epoch 139/200\n",
      "2206/2206 [==============================] - 888s 402ms/step - loss: 3.1216\n",
      "Epoch 140/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 3.1158\n",
      "Epoch 141/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.1023\n",
      "Epoch 142/200\n",
      "2206/2206 [==============================] - 892s 404ms/step - loss: 3.0950\n",
      "Epoch 143/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 3.0956\n",
      "Epoch 144/200\n",
      "1487/2206 [===================>..........] - ETA: 4:49 - loss: 3.0565"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2206/2206 [==============================] - 887s 402ms/step - loss: 3.0842\n",
      "Epoch 146/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.0799\n",
      "Epoch 147/200\n",
      "2206/2206 [==============================] - 888s 403ms/step - loss: 3.0713\n",
      "Epoch 148/200\n",
      "2206/2206 [==============================] - 888s 402ms/step - loss: 3.0670\n",
      "Epoch 149/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 3.0543\n",
      "Epoch 150/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 3.0416\n",
      "Epoch 151/200\n",
      "2206/2206 [==============================] - 888s 403ms/step - loss: 3.0403\n",
      "Epoch 152/200\n",
      "2206/2206 [==============================] - 888s 402ms/step - loss: 3.0326\n",
      "Epoch 153/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 3.0281\n",
      "Epoch 154/200\n",
      "2206/2206 [==============================] - 888s 402ms/step - loss: 3.0228\n",
      "Epoch 155/200\n",
      "2206/2206 [==============================] - 888s 402ms/step - loss: 3.0157\n",
      "Epoch 156/200\n",
      "2206/2206 [==============================] - 888s 402ms/step - loss: 3.0186\n",
      "Epoch 157/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 3.0091\n",
      "Epoch 158/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 3.0000\n",
      "Epoch 159/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 2.9953\n",
      "Epoch 160/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 2.9945\n",
      "Epoch 161/200\n",
      "2206/2206 [==============================] - 888s 403ms/step - loss: 2.9860\n",
      "Epoch 162/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 2.9872\n",
      "Epoch 163/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 2.9977\n",
      "Epoch 164/200\n",
      "2206/2206 [==============================] - 886s 401ms/step - loss: 3.0097\n",
      "Epoch 165/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 3.0089\n",
      "Epoch 166/200\n",
      "2206/2206 [==============================] - 888s 403ms/step - loss: 3.0047\n",
      "Epoch 167/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 2.9961\n",
      "Epoch 168/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 2.9857\n",
      "Epoch 169/200\n",
      "2206/2206 [==============================] - 888s 403ms/step - loss: 2.9808\n",
      "Epoch 170/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 2.9791\n",
      "Epoch 171/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 2.9819\n",
      "Epoch 172/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 2.9735\n",
      "Epoch 173/200\n",
      "2206/2206 [==============================] - 888s 402ms/step - loss: 3.0296\n",
      "Epoch 174/200\n",
      "2206/2206 [==============================] - 886s 402ms/step - loss: 3.1190\n",
      "Epoch 175/200\n",
      "2206/2206 [==============================] - 887s 402ms/step - loss: 3.0903\n",
      "Epoch 176/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 3.0687\n",
      "Epoch 177/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 3.0612\n",
      "Epoch 178/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.0427\n",
      "Epoch 179/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.0289\n",
      "Epoch 180/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 3.0013\n",
      "Epoch 181/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 2.9758\n",
      "Epoch 182/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 2.9550\n",
      "Epoch 183/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 2.9328\n",
      "Epoch 184/200\n",
      "2206/2206 [==============================] - 889s 403ms/step - loss: 2.9141\n",
      "Epoch 185/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 2.9025\n",
      "Epoch 186/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 2.8918\n",
      "Epoch 187/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 2.8795\n",
      "Epoch 188/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 2.8685\n",
      "Epoch 189/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 2.8596\n",
      "Epoch 190/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 2.8494\n",
      "Epoch 191/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 2.8422\n",
      "Epoch 192/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 2.8357\n",
      "Epoch 193/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 2.8323\n",
      "Epoch 194/200\n",
      "2206/2206 [==============================] - 890s 404ms/step - loss: 2.8212\n",
      "Epoch 195/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 2.8040\n",
      "Epoch 196/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 2.8121\n",
      "Epoch 197/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 2.7959\n",
      "Epoch 198/200\n",
      "2206/2206 [==============================] - 890s 403ms/step - loss: 2.7906\n",
      "Epoch 199/200\n",
      "2206/2206 [==============================] - 891s 404ms/step - loss: 2.7850\n",
      "Epoch 200/200\n",
      "2206/2206 [==============================] - 893s 405ms/step - loss: 2.7758\n"
     ]
    }
   ],
   "source": [
    "train_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kqv9bYxUOc-I"
   },
   "source": [
    "### `predict.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WSh0V6T-OyeG"
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = \"weights-improvement-19-4.3037-bigger.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x8geg-cFOqJ9"
   },
   "outputs": [],
   "source": [
    "def generate():\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    # Get all pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab)\n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uuBMeimZOrjt"
   },
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, pitchnames, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    # map between notes and integers and back\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    sequence_length = 100\n",
    "    network_input = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "\n",
    "    return (network_input, normalized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5inpZR9gOttW"
   },
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    # Load the weights to each node\n",
    "    model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "E-O-pHEKOw26"
   },
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = numpy.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = numpy.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zdYDwJdMO6w8"
   },
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Y1cOXpVrO-3f"
   },
   "outputs": [],
   "source": [
    "# generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPdZYyhMPBdX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

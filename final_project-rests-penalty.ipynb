{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8YJcPWLOFOj"
   },
   "source": [
    "### `LSTM.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F0JemjEeN5ZO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 01:36:58.157850: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-22 01:36:59.256962: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-22 01:36:59.257019: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-22 01:36:59.442697: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-22 01:36:59.792756: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "import keras.utils\n",
    "from music21 import converter, instrument, note, chord, stream, duration\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFcX_sgIPbms",
    "outputId": "d7db2bae-ea27-4246-fbb1-f49794c2d6f0"
   },
   "outputs": [],
   "source": [
    "train_files = glob.glob('maestro_v3_2013/*.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UN8drrgBODQn"
   },
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes = get_notes()\n",
    "    # notes = pickle.load('/content/drive/My Drive/Colab Notebooks/final_project_neuro240_files/data/notes')\n",
    "\n",
    "    # get amount of pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    model = create_network(network_input, n_vocab)\n",
    "\n",
    "    train(model, network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1tsJJJEtOKtq"
   },
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in train_files[:90]:\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        for transposition in range(-6, 6):  # Transpose from -6 to +5 semitones\n",
    "            transposed_midi = midi.transpose(transposition)\n",
    "            notes_to_parse = None\n",
    "\n",
    "            try: # file has instrument parts\n",
    "                s2 = instrument.partitionByInstrument(transposed_midi)\n",
    "                notes_to_parse = s2.parts[0].recurse()\n",
    "            except: # file has notes in a flat structure\n",
    "                notes_to_parse = transposed_midi.flat.notes\n",
    "    \n",
    "            for element in notes_to_parse:\n",
    "                if isinstance(element, note.Note):\n",
    "                    # print(str(element.pitch) + \"_\" + str(element.duration.quarterLength))\n",
    "                    notes.append(str(element.pitch) + \"_\" + str(element.duration.quarterLength))\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                elif isinstance(element, note.Rest):\n",
    "                    notes.append(\"R\")\n",
    "    # try:\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    print(\"Notes saved\")\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "rXARdAY4ONDP"
   },
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = keras.utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "gAs4dAPhOQMU"
   },
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Yawf61mHOSeV"
   },
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    filepath = \"Rest-Duration-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(network_input, network_output, epochs=200, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bxx-k1Y7OUCv",
    "outputId": "84a1a3f5-34e1-4c37-96e3-975a95ba9c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_12_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_19_R2_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_02_R1_2013_wav--1.midi\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_network\u001b[39m():\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Train a Neural Network to generate music \"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     notes \u001b[38;5;241m=\u001b[39m \u001b[43mget_notes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# notes = pickle.load('/content/drive/My Drive/Colab Notebooks/final_project_neuro240_files/data/notes')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# get amount of pitch names\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     n_vocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(notes))\n",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m, in \u001b[0;36mget_notes\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m notes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m train_files[:\u001b[38;5;241m90\u001b[39m]:\n\u001b[0;32m----> 6\u001b[0m     midi \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m file)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transposition \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m):  \u001b[38;5;66;03m# Transpose from -6 to +5 semitones\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/converter/__init__.py:1409\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(value, forceSource, number, format, **keywords)\u001b[0m\n\u001b[1;32m   1406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parseData(value, number\u001b[38;5;241m=\u001b[39mnumber, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkeywords)\n\u001b[1;32m   1407\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbytes\u001b[39m)\n\u001b[1;32m   1408\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m _osCanLoad(valueStr)):\n\u001b[0;32m-> 1409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparseFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalueStr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mforceSource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforceSource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbytes\u001b[39m)\n\u001b[1;32m   1412\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m _osCanLoad(common\u001b[38;5;241m.\u001b[39mcleanpath(valueStr))):\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parseFile(common\u001b[38;5;241m.\u001b[39mcleanpath(valueStr), number\u001b[38;5;241m=\u001b[39mnumber, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m,\n\u001b[1;32m   1414\u001b[0m                      forceSource\u001b[38;5;241m=\u001b[39mforceSource, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkeywords)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/converter/__init__.py:1263\u001b[0m, in \u001b[0;36mparseFile\u001b[0;34m(fp, number, format, forceSource, **keywords)\u001b[0m\n\u001b[1;32m   1261\u001b[0m v \u001b[38;5;241m=\u001b[39m Converter()\n\u001b[1;32m   1262\u001b[0m fp \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mcleanpath(fp, returnPathlib\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1263\u001b[0m \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparseFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforceSource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforceSource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mTYPE_CHECKING:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v\u001b[38;5;241m.\u001b[39mstream, (stream\u001b[38;5;241m.\u001b[39mScore, stream\u001b[38;5;241m.\u001b[39mPart, stream\u001b[38;5;241m.\u001b[39mOpus))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/converter/__init__.py:646\u001b[0m, in \u001b[0;36mConverter.parseFile\u001b[0;34m(self, fp, number, format, forceSource, storePickle, **keywords)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    645\u001b[0m     environLocal\u001b[38;5;241m.\u001b[39mprintDebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading original version\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 646\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparseFileNoPickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforceSource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m writePickle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m fpPickle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m storePickle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;66;03m# save the stream to disk...\u001b[39;00m\n\u001b[1;32m    649\u001b[0m         environLocal\u001b[38;5;241m.\u001b[39mprintDebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreezing Pickle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/converter/__init__.py:568\u001b[0m, in \u001b[0;36mConverter.parseFileNoPickle\u001b[0;34m(self, fp, number, format, forceSource, **keywords)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubConverter\u001b[38;5;241m.\u001b[39mkeywords \u001b[38;5;241m=\u001b[39m keywords\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 568\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubConverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparseFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeywords\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConverterFileException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile is not in a correct format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/converter/subConverters.py:1055\u001b[0m, in \u001b[0;36mConverterMidi.parseFile\u001b[0;34m(self, filePath, number, **keywords)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;124;03mGet MIDI data from a file path.\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;03min defaults.quantizationQuarterLengthDivisors. (Default: (4, 3)).\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmusic21\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmidi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m translate \u001b[38;5;28;01mas\u001b[39;00m midiTranslate\n\u001b[0;32m-> 1055\u001b[0m \u001b[43mmidiTranslate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmidiFilePathToStream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilePath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputM21\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/midi/translate.py:2721\u001b[0m, in \u001b[0;36mmidiFilePathToStream\u001b[0;34m(filePath, inputM21, **keywords)\u001b[0m\n\u001b[1;32m   2719\u001b[0m mf\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   2720\u001b[0m mf\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 2721\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmidiFileToStream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputM21\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputM21\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/midi/translate.py:2892\u001b[0m, in \u001b[0;36mmidiFileToStream\u001b[0;34m(mf, inputM21, quantizePost, **keywords)\u001b[0m\n\u001b[1;32m   2888\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions21\u001b[38;5;241m.\u001b[39mStreamException(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno tracks are defined in this MIDI file.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;66;03m# create a stream for each track\u001b[39;00m\n\u001b[1;32m   2891\u001b[0m \u001b[38;5;66;03m# may need to check if tracks actually have event data\u001b[39;00m\n\u001b[0;32m-> 2892\u001b[0m \u001b[43mmidiTracksToStreams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2893\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mticksPerQuarter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mticksPerQuarterNote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2894\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mquantizePost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantizePost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2895\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minputM21\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2896\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2897\u001b[0m \u001b[38;5;66;03m# s._setMidiTracks(mf.tracks, mf.ticksPerQuarterNote)\u001b[39;00m\n\u001b[1;32m   2899\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/midi/translate.py:2629\u001b[0m, in \u001b[0;36mmidiTracksToStreams\u001b[0;34m(midiTracks, ticksPerQuarter, quantizePost, inputM21, **keywords)\u001b[0m\n\u001b[1;32m   2626\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2627\u001b[0m         streamPart \u001b[38;5;241m=\u001b[39m conductorPart\n\u001b[0;32m-> 2629\u001b[0m     \u001b[43mmidiTrackToStream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2630\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mticksPerQuarter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mticksPerQuarter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2631\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mquantizePost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantizePost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2632\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minputM21\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamPart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mconductorPart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconductorPart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2634\u001b[0m \u001b[43m                      \u001b[49m\u001b[43misFirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfirstTrackWithNotes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/midi/translate.py:2111\u001b[0m, in \u001b[0;36mmidiTrackToStream\u001b[0;34m(mt, ticksPerQuarter, quantizePost, inputM21, conductorPart, isFirst, quarterLengthDivisors, **keywords)\u001b[0m\n\u001b[1;32m   2109\u001b[0m s\u001b[38;5;241m.\u001b[39mmakeTies(inPlace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# always need to fill gaps, as rests are not found in any other way\u001b[39;00m\n\u001b[0;32m-> 2111\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakeRests\u001b[49m\u001b[43m(\u001b[49m\u001b[43minPlace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfillGaps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeRangeFromBarDuration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/stream/base.py:6660\u001b[0m, in \u001b[0;36mStream.makeRests\u001b[0;34m(self, refStreamOrTimeRange, fillGaps, timeRangeFromBarDuration, inPlace, hideRests)\u001b[0m\n\u001b[1;32m   6647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmakeRests\u001b[39m(\n\u001b[1;32m   6648\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   6649\u001b[0m     refStreamOrTimeRange\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6653\u001b[0m     hideRests\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   6654\u001b[0m ):\n\u001b[1;32m   6655\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   6656\u001b[0m \u001b[38;5;124;03m    Calls :py:func:`~music21.stream.makeNotation.makeRests`.\u001b[39;00m\n\u001b[1;32m   6657\u001b[0m \n\u001b[1;32m   6658\u001b[0m \u001b[38;5;124;03m    * Changed in v7, inPlace=False by default.\u001b[39;00m\n\u001b[1;32m   6659\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m-> 6660\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmakeNotation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakeRests\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6661\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefStreamOrTimeRange\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefStreamOrTimeRange\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfillGaps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfillGaps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeRangeFromBarDuration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeRangeFromBarDuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6665\u001b[0m \u001b[43m        \u001b[49m\u001b[43minPlace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minPlace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhideRests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhideRests\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6667\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/stream/makeNotation.py:899\u001b[0m, in \u001b[0;36mmakeRests\u001b[0;34m(s, refStreamOrTimeRange, fillGaps, timeRangeFromBarDuration, inPlace, hideRests)\u001b[0m\n\u001b[1;32m    895\u001b[0m             oHighTarget \u001b[38;5;241m=\u001b[39m oHighTargetForMeasure(m\u001b[38;5;241m=\u001b[39mmaybe_measure, ts\u001b[38;5;241m=\u001b[39mrefStreamOrTimeRange)\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m returnObj\u001b[38;5;241m.\u001b[39mhasMeasures():\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;66;03m# This could be optimized to save some context searches,\u001b[39;00m\n\u001b[1;32m    898\u001b[0m         \u001b[38;5;66;03m# but at the cost of readability.\u001b[39;00m\n\u001b[0;32m--> 899\u001b[0m         oHighTarget \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\n\u001b[1;32m    900\u001b[0m             m\u001b[38;5;241m.\u001b[39mbarDuration\u001b[38;5;241m.\u001b[39mquarterLength \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m returnObj\u001b[38;5;241m.\u001b[39mgetElementsByClass(stream\u001b[38;5;241m.\u001b[39mMeasure)\n\u001b[1;32m    901\u001b[0m         )\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# If the above search didn't run or still yielded 0.0, use refStreamOrTimeRange\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m oHighTarget \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/stream/makeNotation.py:900\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    895\u001b[0m             oHighTarget \u001b[38;5;241m=\u001b[39m oHighTargetForMeasure(m\u001b[38;5;241m=\u001b[39mmaybe_measure, ts\u001b[38;5;241m=\u001b[39mrefStreamOrTimeRange)\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m returnObj\u001b[38;5;241m.\u001b[39mhasMeasures():\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;66;03m# This could be optimized to save some context searches,\u001b[39;00m\n\u001b[1;32m    898\u001b[0m         \u001b[38;5;66;03m# but at the cost of readability.\u001b[39;00m\n\u001b[1;32m    899\u001b[0m         oHighTarget \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\n\u001b[0;32m--> 900\u001b[0m             \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbarDuration\u001b[49m\u001b[38;5;241m.\u001b[39mquarterLength \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m returnObj\u001b[38;5;241m.\u001b[39mgetElementsByClass(stream\u001b[38;5;241m.\u001b[39mMeasure)\n\u001b[1;32m    901\u001b[0m         )\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# If the above search didn't run or still yielded 0.0, use refStreamOrTimeRange\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m oHighTarget \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/stream/base.py:13408\u001b[0m, in \u001b[0;36mMeasure.barDuration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  13406\u001b[0m     ts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeSignature\n\u001b[1;32m  13407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# do a context-based search\u001b[39;00m\n\u001b[0;32m> 13408\u001b[0m     tsStream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTimeSignatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearchContext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m  13409\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mreturnDefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m  13410\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43msortByCreationTime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m  13411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tsStream:\n\u001b[1;32m  13412\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/stream/base.py:5669\u001b[0m, in \u001b[0;36mStream.getTimeSignatures\u001b[0;34m(self, searchContext, returnDefault, recurse, sortByCreationTime)\u001b[0m\n\u001b[1;32m   5666\u001b[0m \u001b[38;5;66;03m# search activeSite Streams through contexts\u001b[39;00m\n\u001b[1;32m   5667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m post \u001b[38;5;129;01mand\u001b[39;00m searchContext:\n\u001b[1;32m   5668\u001b[0m     \u001b[38;5;66;03m# sort by time to search the most recent objects\u001b[39;00m\n\u001b[0;32m-> 5669\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetContextByClass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTimeSignature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msortByCreationTime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msortByCreationTime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5670\u001b[0m     \u001b[38;5;66;03m# obj = self.previous(meter.TimeSignature)\u001b[39;00m\n\u001b[1;32m   5671\u001b[0m     \u001b[38;5;66;03m# environLocal.printDebug(['getTimeSignatures(): searching contexts: results', obj])\u001b[39;00m\n\u001b[1;32m   5672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/base.py:1756\u001b[0m, in \u001b[0;36mMusic21Object.getContextByClass\u001b[0;34m(self, className, getElementMethod, sortByCreationTime, followDerivation, priorityTargetOnly)\u001b[0m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m getElementMethod \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m NOT_SELF_METHODS:  \u001b[38;5;66;03m# for 'After' we can't do the\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m         \u001b[38;5;66;03m# containing site because that comes before.\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m site  \u001b[38;5;66;03m# if the site itself is the context, return it...\u001b[39;00m\n\u001b[0;32m-> 1756\u001b[0m contextEl \u001b[38;5;241m=\u001b[39m \u001b[43mpayloadExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mflatten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msemiFlat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m                             \u001b[49m\u001b[43minnerPositionStart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositionStart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m contextEl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m wellFormed(contextEl, site):\n\u001b[1;32m   1760\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/base.py:1592\u001b[0m, in \u001b[0;36mMusic21Object.getContextByClass.<locals>.payloadExtractor\u001b[0;34m(checkSite, flatten, innerPositionStart)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;124;03mchange the site (stream) to a Tree (using caches if possible),\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;124;03mthen find the node before (or after) the positionStart and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;124;03mflatten can be True, 'semiFlat', or False.\u001b[39;00m\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m classList \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m className \u001b[38;5;28;01melse\u001b[39;00m (className,)\n\u001b[0;32m-> 1592\u001b[0m siteTree \u001b[38;5;241m=\u001b[39m \u001b[43mcheckSite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflatten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassList\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassList\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m getElementMethod \u001b[38;5;129;01min\u001b[39;00m OFFSET_METHODS:\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;66;03m# these methods match only by offset.  Used in .getBeat among other places\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m getElementMethod \u001b[38;5;129;01min\u001b[39;00m (ElementSearch\u001b[38;5;241m.\u001b[39mBEFORE_OFFSET,\n\u001b[1;32m   1596\u001b[0m                             ElementSearch\u001b[38;5;241m.\u001b[39mAT_OR_AFTER_OFFSET):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/stream/core.py:561\u001b[0m, in \u001b[0;36mStreamCore.asTree\u001b[0;34m(self, flatten, classList, useTimespans, groupOffsets)\u001b[0m\n\u001b[1;32m    559\u001b[0m cacheKey \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melementTree\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(hashedAttributes)\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cacheKey \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[cacheKey] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 561\u001b[0m     hashedElementTree \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromStream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masTree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mflatten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mclassList\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassList\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43museTimespans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43museTimespans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mgroupOffsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroupOffsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[cacheKey] \u001b[38;5;241m=\u001b[39m hashedElementTree\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[cacheKey]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/tree/fromStream.py:289\u001b[0m, in \u001b[0;36masTree\u001b[0;34m(inputStream, flatten, classList, useTimespans, groupOffsets)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m makeFastShallowTreeFromSortedStream(inputStream,\n\u001b[1;32m    286\u001b[0m                                                outputTree\u001b[38;5;241m=\u001b[39moutputTree,\n\u001b[1;32m    287\u001b[0m                                                classList\u001b[38;5;241m=\u001b[39mclassList)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecurseGetTreeByClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputStream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcurrentParentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputStream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43minitialOffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/tree/fromStream.py:227\u001b[0m, in \u001b[0;36masTree.<locals>.recurseGetTreeByClass\u001b[0;34m(innerStream, currentParentage, initialOffset, inner_outputTree)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# do this to avoid munging activeSites\u001b[39;00m\n\u001b[1;32m    226\u001b[0m innerStreamElements \u001b[38;5;241m=\u001b[39m innerStream\u001b[38;5;241m.\u001b[39m_elements[:] \u001b[38;5;241m+\u001b[39m innerStream\u001b[38;5;241m.\u001b[39m_endElements\n\u001b[0;32m--> 227\u001b[0m parentEndTime \u001b[38;5;241m=\u001b[39m initialOffset \u001b[38;5;241m+\u001b[39m \u001b[43mlastParentage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[38;5;241m.\u001b[39mquarterLength\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m innerStreamElements:\n\u001b[1;32m    230\u001b[0m     flatOffset \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mopFrac(lastParentage\u001b[38;5;241m.\u001b[39melementOffset(element) \u001b[38;5;241m+\u001b[39m initialOffset)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/stream/base.py:8577\u001b[0m, in \u001b[0;36mStream.duration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   8536\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   8537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mduration\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmusic21.duration.Duration\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   8538\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   8539\u001b[0m \u001b[38;5;124;03m    Returns the total duration of the Stream, from the beginning of the\u001b[39;00m\n\u001b[1;32m   8540\u001b[0m \u001b[38;5;124;03m    stream until the end of the final element.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8575\u001b[0m \u001b[38;5;124;03m    4.0\u001b[39;00m\n\u001b[1;32m   8576\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m-> 8577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getDuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/stream/base.py:8517\u001b[0m, in \u001b[0;36mStream._getDuration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   8514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuration\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m   8515\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   8516\u001b[0m     \u001b[38;5;66;03m# environLocal.printDebug(['creating new duration based on highest time'])\u001b[39;00m\n\u001b[0;32m-> 8517\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuration\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m duration\u001b[38;5;241m.\u001b[39mDuration(quarterLength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhighestTime\u001b[49m)\n\u001b[1;32m   8518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuration\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/stream/base.py:8442\u001b[0m, in \u001b[0;36mStream.highestTime\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   8432\u001b[0m \u001b[38;5;66;03m# TODO: optimize for a faster way of doing this.\u001b[39;00m\n\u001b[1;32m   8433\u001b[0m \u001b[38;5;66;03m#     but cannot simply look at the last element even if isSorted\u001b[39;00m\n\u001b[1;32m   8434\u001b[0m \u001b[38;5;66;03m#     because what if the penultimate\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8438\u001b[0m \u001b[38;5;66;03m#     textExpression (ql=0) at 0.25 --\u001b[39;00m\n\u001b[1;32m   8439\u001b[0m \u001b[38;5;66;03m#     isSorted would be true, but highestTime should be 4.0 not 0.25\u001b[39;00m\n\u001b[1;32m   8440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elements:\n\u001b[1;32m   8441\u001b[0m     candidateOffset \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melementOffset(e)\n\u001b[0;32m-> 8442\u001b[0m                        \u001b[38;5;241m+\u001b[39m \u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquarterLength\u001b[49m)\n\u001b[1;32m   8443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m candidateOffset \u001b[38;5;241m>\u001b[39m highestTimeSoFar:\n\u001b[1;32m   8444\u001b[0m         highestTimeSoFar \u001b[38;5;241m=\u001b[39m candidateOffset\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/music21/duration.py:2924\u001b[0m, in \u001b[0;36mDuration._getQuarterLength\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2921\u001b[0m         tot \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m.\u001b[39mquarterLength\n\u001b[1;32m   2922\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tot\n\u001b[0;32m-> 2924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getQuarterLength\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OffsetQL:\n\u001b[1;32m   2925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quarterLengthNeedsUpdating:\n\u001b[1;32m   2926\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_updateQuarterLength()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kqv9bYxUOc-I"
   },
   "source": [
    "### `predict.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WSh0V6T-OyeG"
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = \"Rest-Duration-weights-improvement-158-3.1368.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_rest_probability(predictions, rest_idx, penalty_factor=0.5):\n",
    "    \"\"\"Reduce the probability of predicting a rest by a penalty factor.\"\"\"\n",
    "    predictions[0, rest_idx] *= penalty_factor\n",
    "    predictions /= numpy.sum(predictions)  # Re-normalize probabilities\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "x8geg-cFOqJ9"
   },
   "outputs": [],
   "source": [
    "def generate():\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    # Get all pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab)\n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uuBMeimZOrjt"
   },
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, pitchnames, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    # map between notes and integers and back\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    sequence_length = 100\n",
    "    network_input = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "\n",
    "    return (network_input, normalized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5inpZR9gOttW"
   },
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    # Load the weights to each node\n",
    "    model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "E-O-pHEKOw26"
   },
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = numpy.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    rest_index = note_to_int.get('R', None)  # Safely get rest index, if it exists\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        # Adjust probability for rests, if rest index is known\n",
    "        if rest_index is not None:\n",
    "            prediction = adjust_rest_probability(prediction, rest_index, penalty_factor=0.1)\n",
    "\n",
    "        index = numpy.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zdYDwJdMO6w8"
   },
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                try:\n",
    "                    new_note = note.Note(current_note.split('_')[0])\n",
    "                    new_note.storedInstrument = instrument.Piano()\n",
    "                    notes.append(new_note)\n",
    "                except:\n",
    "                    try:\n",
    "                        new_note = note.Note(current_note)\n",
    "                        new_note.storedInstrument = instrument.Piano()\n",
    "                        notes.append(new_note)\n",
    "                    except:\n",
    "                        try:\n",
    "                            new_note = note.Note(int(current_note))\n",
    "                            new_note.storedInstrument = instrument.Piano()\n",
    "                            notes.append(new_note)\n",
    "                        except:\n",
    "                            pass\n",
    "            try:\n",
    "                new_chord = chord.Chord(notes)\n",
    "                new_chord.offset = offset\n",
    "                output_notes.append(new_chord)\n",
    "            except:\n",
    "                pass\n",
    "        # pattern is a rest\n",
    "        elif pattern == \"R\":\n",
    "            # print(\"rest detected\")\n",
    "            new_rest = note.Rest()\n",
    "            # new_rest.duration.quarterLength = 0.5\n",
    "            new_rest.storedInstrument = instrument.Piano()\n",
    "            new_rest.offset = offset\n",
    "            output_notes.append(new_rest)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            # print(pattern)\n",
    "            note_pitch, note_length = pattern.split(\"_\")\n",
    "            # print((note_pitch, note_length))\n",
    "            try:\n",
    "                new_note = note.Note(note_pitch)\n",
    "                try:\n",
    "                    new_note.duration = duration.Duration(float(note_length))\n",
    "                    new_note.storedInstrument = instrument.Piano()\n",
    "                    new_note.offset = offset\n",
    "                    output_notes.append(new_note)\n",
    "                except:\n",
    "                    new_note.storedInstrument = instrument.Piano()\n",
    "                    new_note.offset = offset\n",
    "                    output_notes.append(new_note)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output_new_durations_penalty3.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Y1cOXpVrO-3f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPdZYyhMPBdX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

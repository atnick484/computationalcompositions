{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8YJcPWLOFOj"
   },
   "source": [
    "### `LSTM.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F0JemjEeN5ZO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 15:07:30.962323: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-10 15:07:31.007378: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-10 15:07:31.007433: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-10 15:07:31.008517: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-10 15:07:31.015702: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "import keras.utils\n",
    "from music21 import converter, instrument, note, chord, stream, duration\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFcX_sgIPbms",
    "outputId": "d7db2bae-ea27-4246-fbb1-f49794c2d6f0"
   },
   "outputs": [],
   "source": [
    "train_files = glob.glob('maestro_v3_2013/*.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UN8drrgBODQn"
   },
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes = get_notes()\n",
    "    # notes = pickle.load('/content/drive/My Drive/Colab Notebooks/final_project_neuro240_files/data/notes')\n",
    "\n",
    "    # get amount of pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    model = create_network(network_input, n_vocab)\n",
    "\n",
    "    train(model, network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1tsJJJEtOKtq"
   },
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in train_files[:90]:\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse()\n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                # print(str(element.pitch) + \"_\" + str(element.duration.quarterLength))\n",
    "                notes.append(str(element.pitch) + \"_\" + str(element.duration.quarterLength))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "            elif isinstance(element, note.Rest):\n",
    "                notes.append(\"R\")\n",
    "    # try:\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    print(\"Notes saved\")\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rXARdAY4ONDP"
   },
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = keras.utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gAs4dAPhOQMU"
   },
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Yawf61mHOSeV"
   },
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    filepath = \"Rest-Duration-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(network_input, network_output, epochs=200, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bxx-k1Y7OUCv",
    "outputId": "84a1a3f5-34e1-4c37-96e3-975a95ba9c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_12_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_19_R2_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_02_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_17_R3_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_07_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_08_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_17_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_06_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_15_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_07_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_16_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_18_R3_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_14_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_03_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_03_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_07_R3_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_15_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_11_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_13_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_04_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_08_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_02_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_10_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_11_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_05_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_02_R1_2013_wav--5.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_08_R2_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_09_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_17_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_19_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_18_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_18_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_03_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_12_R3_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_14_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_11_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_10_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_04_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_09_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_08_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_19_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_14_R2_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_15_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_17_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_08_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_15_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_06_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_12_R1_2013_wav--5.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_12_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_14_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_17_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_05_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_13_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_11_R2_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_07_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_08_R3_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_02_R3_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_18_R2_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_11_R3_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_10_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_11_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_02_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_03_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_10_13_Group_MID--AUDIO_12_R3_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_18_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_18_R3_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_16_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_17_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_8_13_Group__MID--AUDIO_15_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_08_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_07_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_15_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_6_13_Group__MID--AUDIO_09_R1_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_05_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_04_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_08_R3_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_02_R2_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_13_R1_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_04_R1_2013_wav--4.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_8_13_Group__MID--AUDIO_03_R2_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_8_13_Group__MID--AUDIO_12_R2_2013_wav--1.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_7_13_Group__MID--AUDIO_14_R1_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_03_7_10_13_Group_MID--AUDIO_15_R3_2013_wav--2.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_07_R3_2013_wav--3.midi\n",
      "Parsing maestro_v3_2013/ORIG-MIDI_02_7_6_13_Group__MID--AUDIO_06_R1_2013_wav--1.midi\n",
      "Notes saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 15:09:13.871260: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 15:09:13.880823: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 15:09:13.883707: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 15:09:13.887527: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L355\n",
      "2024-04-10 15:09:13.890338: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 15:09:13.892978: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 15:09:14.080319: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 15:09:14.081792: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 15:09:14.083163: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 15:09:14.084502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n",
      "2024-04-10 15:09:14.538136: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 15:09:33.988137: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "2024-04-10 15:09:35.040305: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f0b00a4b6e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-10 15:09:35.040361: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-04-10 15:09:35.045965: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712761775.118579   21974 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2565/2565 [==============================] - ETA: 0s - loss: 5.0605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2565/2565 [==============================] - 1057s 408ms/step - loss: 5.0605\n",
      "Epoch 2/200\n",
      "2565/2565 [==============================] - 1059s 413ms/step - loss: 4.7363\n",
      "Epoch 3/200\n",
      "2565/2565 [==============================] - 1081s 421ms/step - loss: 4.7319\n",
      "Epoch 4/200\n",
      "2565/2565 [==============================] - 1089s 424ms/step - loss: 4.7201\n",
      "Epoch 5/200\n",
      "2565/2565 [==============================] - 1090s 425ms/step - loss: 4.7181\n",
      "Epoch 6/200\n",
      "2565/2565 [==============================] - 1088s 424ms/step - loss: 4.7176\n",
      "Epoch 7/200\n",
      "2565/2565 [==============================] - 1086s 424ms/step - loss: 4.7115\n",
      "Epoch 8/200\n",
      "2565/2565 [==============================] - 1086s 423ms/step - loss: 4.7090\n",
      "Epoch 9/200\n",
      "2565/2565 [==============================] - 1089s 425ms/step - loss: 4.7070\n",
      "Epoch 10/200\n",
      "2565/2565 [==============================] - 1091s 425ms/step - loss: 4.6977\n",
      "Epoch 11/200\n",
      "2565/2565 [==============================] - 1088s 424ms/step - loss: 4.6877\n",
      "Epoch 12/200\n",
      "2565/2565 [==============================] - 1091s 425ms/step - loss: 4.6767\n",
      "Epoch 13/200\n",
      "2565/2565 [==============================] - 1092s 426ms/step - loss: 4.6553\n",
      "Epoch 14/200\n",
      "2565/2565 [==============================] - 1088s 424ms/step - loss: 4.6318\n",
      "Epoch 15/200\n",
      "2565/2565 [==============================] - 1091s 425ms/step - loss: 4.6125\n",
      "Epoch 16/200\n",
      "2565/2565 [==============================] - 1092s 426ms/step - loss: 4.5891\n",
      "Epoch 17/200\n",
      "2565/2565 [==============================] - 1090s 425ms/step - loss: 4.5663\n",
      "Epoch 18/200\n",
      "2565/2565 [==============================] - 1092s 426ms/step - loss: 4.5450\n",
      "Epoch 19/200\n",
      "2565/2565 [==============================] - 1087s 424ms/step - loss: 4.5287\n",
      "Epoch 20/200\n",
      "2565/2565 [==============================] - 1098s 428ms/step - loss: 4.5193\n",
      "Epoch 21/200\n",
      "2565/2565 [==============================] - 1088s 424ms/step - loss: 4.5133\n",
      "Epoch 22/200\n",
      "2565/2565 [==============================] - 1059s 413ms/step - loss: 4.5101\n",
      "Epoch 23/200\n",
      "2565/2565 [==============================] - 1044s 407ms/step - loss: 4.5043\n",
      "Epoch 24/200\n",
      "2565/2565 [==============================] - 1043s 407ms/step - loss: 4.4931\n",
      "Epoch 25/200\n",
      "2565/2565 [==============================] - 1030s 401ms/step - loss: 4.4758\n",
      "Epoch 26/200\n",
      "2565/2565 [==============================] - 1067s 416ms/step - loss: 4.4617\n",
      "Epoch 27/200\n",
      "2565/2565 [==============================] - 1093s 426ms/step - loss: 4.4437\n",
      "Epoch 28/200\n",
      "2565/2565 [==============================] - 1084s 422ms/step - loss: 4.4291\n",
      "Epoch 29/200\n",
      "2565/2565 [==============================] - 1080s 421ms/step - loss: 4.4143\n",
      "Epoch 30/200\n",
      "2565/2565 [==============================] - 1087s 424ms/step - loss: 4.3998\n",
      "Epoch 31/200\n",
      "2565/2565 [==============================] - 1090s 425ms/step - loss: 4.3876\n",
      "Epoch 32/200\n",
      "2565/2565 [==============================] - 1086s 423ms/step - loss: 4.3739\n",
      "Epoch 33/200\n",
      "2565/2565 [==============================] - 1087s 424ms/step - loss: 4.3595\n",
      "Epoch 34/200\n",
      "2565/2565 [==============================] - 1083s 422ms/step - loss: 4.3484\n",
      "Epoch 35/200\n",
      "2565/2565 [==============================] - 1078s 420ms/step - loss: 4.3378\n",
      "Epoch 36/200\n",
      "2565/2565 [==============================] - 1084s 423ms/step - loss: 4.3231\n",
      "Epoch 37/200\n",
      "2565/2565 [==============================] - 1088s 424ms/step - loss: 4.3099\n",
      "Epoch 38/200\n",
      "2565/2565 [==============================] - 1084s 423ms/step - loss: 4.2928\n",
      "Epoch 39/200\n",
      "2565/2565 [==============================] - 1084s 423ms/step - loss: 4.2789\n",
      "Epoch 40/200\n",
      "2565/2565 [==============================] - 1081s 421ms/step - loss: 4.2647\n",
      "Epoch 41/200\n",
      "2565/2565 [==============================] - 1086s 423ms/step - loss: 4.2537\n",
      "Epoch 42/200\n",
      "2565/2565 [==============================] - 1097s 428ms/step - loss: 4.2421\n",
      "Epoch 43/200\n",
      "2565/2565 [==============================] - 1101s 429ms/step - loss: 4.2328\n",
      "Epoch 44/200\n",
      "2565/2565 [==============================] - 1096s 427ms/step - loss: 4.2188\n",
      "Epoch 45/200\n",
      "2565/2565 [==============================] - 1050s 410ms/step - loss: 4.2122\n",
      "Epoch 46/200\n",
      "2565/2565 [==============================] - 1024s 399ms/step - loss: 4.2032\n",
      "Epoch 47/200\n",
      "2565/2565 [==============================] - 1024s 399ms/step - loss: 4.1939\n",
      "Epoch 48/200\n",
      "2565/2565 [==============================] - 1024s 399ms/step - loss: 4.1854\n",
      "Epoch 49/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 4.1755\n",
      "Epoch 50/200\n",
      "2565/2565 [==============================] - 1029s 401ms/step - loss: 4.1637\n",
      "Epoch 51/200\n",
      "2565/2565 [==============================] - 1081s 421ms/step - loss: 4.1548\n",
      "Epoch 52/200\n",
      "2565/2565 [==============================] - 1047s 408ms/step - loss: 4.1466\n",
      "Epoch 53/200\n",
      "2565/2565 [==============================] - 1041s 406ms/step - loss: 4.1366\n",
      "Epoch 54/200\n",
      "2565/2565 [==============================] - 1040s 406ms/step - loss: 4.1242\n",
      "Epoch 55/200\n",
      "2565/2565 [==============================] - 1039s 405ms/step - loss: 4.1188\n",
      "Epoch 56/200\n",
      "2565/2565 [==============================] - 1040s 405ms/step - loss: 4.1090\n",
      "Epoch 57/200\n",
      "2565/2565 [==============================] - 1034s 403ms/step - loss: 4.0996\n",
      "Epoch 58/200\n",
      "2565/2565 [==============================] - 1037s 404ms/step - loss: 4.0892\n",
      "Epoch 59/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 4.0844\n",
      "Epoch 60/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 4.0740\n",
      "Epoch 61/200\n",
      "2565/2565 [==============================] - 1028s 401ms/step - loss: 4.0602\n",
      "Epoch 62/200\n",
      "2565/2565 [==============================] - 1043s 407ms/step - loss: 4.0511\n",
      "Epoch 63/200\n",
      "2565/2565 [==============================] - 1039s 405ms/step - loss: 4.0427\n",
      "Epoch 64/200\n",
      "2565/2565 [==============================] - 1051s 410ms/step - loss: 4.0339\n",
      "Epoch 65/200\n",
      "2565/2565 [==============================] - 1040s 406ms/step - loss: 4.0218\n",
      "Epoch 66/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 4.0100\n",
      "Epoch 67/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 4.0011\n",
      "Epoch 68/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.9888\n",
      "Epoch 69/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.9736\n",
      "Epoch 70/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.9626\n",
      "Epoch 71/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.9453\n",
      "Epoch 72/200\n",
      "2565/2565 [==============================] - 1024s 399ms/step - loss: 3.9361\n",
      "Epoch 73/200\n",
      "2565/2565 [==============================] - 1032s 402ms/step - loss: 3.9244\n",
      "Epoch 74/200\n",
      "2565/2565 [==============================] - 1049s 409ms/step - loss: 3.9173\n",
      "Epoch 75/200\n",
      "2565/2565 [==============================] - 1049s 409ms/step - loss: 3.9063\n",
      "Epoch 76/200\n",
      "2565/2565 [==============================] - 1029s 401ms/step - loss: 3.8932\n",
      "Epoch 77/200\n",
      "2565/2565 [==============================] - 1040s 406ms/step - loss: 3.8778\n",
      "Epoch 78/200\n",
      "2565/2565 [==============================] - 1050s 409ms/step - loss: 3.8607\n",
      "Epoch 79/200\n",
      "2565/2565 [==============================] - 1036s 404ms/step - loss: 3.8445\n",
      "Epoch 80/200\n",
      "2565/2565 [==============================] - 1027s 401ms/step - loss: 3.8352\n",
      "Epoch 81/200\n",
      "2565/2565 [==============================] - 1027s 400ms/step - loss: 3.8219\n",
      "Epoch 82/200\n",
      "2565/2565 [==============================] - 1052s 410ms/step - loss: 3.8089\n",
      "Epoch 83/200\n",
      "2565/2565 [==============================] - 1032s 402ms/step - loss: 3.7889\n",
      "Epoch 84/200\n",
      "2565/2565 [==============================] - 1072s 418ms/step - loss: 3.7770\n",
      "Epoch 85/200\n",
      "2565/2565 [==============================] - 1078s 420ms/step - loss: 3.7623\n",
      "Epoch 86/200\n",
      "2565/2565 [==============================] - 1086s 424ms/step - loss: 3.7478\n",
      "Epoch 87/200\n",
      "2565/2565 [==============================] - 1081s 422ms/step - loss: 3.7374\n",
      "Epoch 88/200\n",
      "2565/2565 [==============================] - 1087s 424ms/step - loss: 3.7241\n",
      "Epoch 89/200\n",
      "2565/2565 [==============================] - 1087s 424ms/step - loss: 3.7168\n",
      "Epoch 90/200\n",
      "2565/2565 [==============================] - 1091s 425ms/step - loss: 3.7097\n",
      "Epoch 91/200\n",
      "2565/2565 [==============================] - 1089s 424ms/step - loss: 3.7010\n",
      "Epoch 92/200\n",
      "2565/2565 [==============================] - 1090s 425ms/step - loss: 3.6911\n",
      "Epoch 93/200\n",
      "2565/2565 [==============================] - 1087s 424ms/step - loss: 3.6756\n",
      "Epoch 94/200\n",
      "2565/2565 [==============================] - 1092s 426ms/step - loss: 3.6642\n",
      "Epoch 95/200\n",
      "2565/2565 [==============================] - 1095s 427ms/step - loss: 3.6526\n",
      "Epoch 96/200\n",
      "2565/2565 [==============================] - 1091s 425ms/step - loss: 3.6407\n",
      "Epoch 97/200\n",
      "2565/2565 [==============================] - 1087s 424ms/step - loss: 3.6268\n",
      "Epoch 98/200\n",
      "2565/2565 [==============================] - 1089s 425ms/step - loss: 3.6163\n",
      "Epoch 99/200\n",
      "2565/2565 [==============================] - 1093s 426ms/step - loss: 3.5957\n",
      "Epoch 100/200\n",
      "2565/2565 [==============================] - 1091s 425ms/step - loss: 3.5745\n",
      "Epoch 101/200\n",
      "2565/2565 [==============================] - 1094s 427ms/step - loss: 3.5576\n",
      "Epoch 102/200\n",
      "2565/2565 [==============================] - 1095s 427ms/step - loss: 3.5467\n",
      "Epoch 103/200\n",
      "2565/2565 [==============================] - 1088s 424ms/step - loss: 3.5379\n",
      "Epoch 104/200\n",
      "2565/2565 [==============================] - 1028s 401ms/step - loss: 3.5245\n",
      "Epoch 105/200\n",
      "2565/2565 [==============================] - 1027s 400ms/step - loss: 3.5132\n",
      "Epoch 106/200\n",
      "2565/2565 [==============================] - 1028s 401ms/step - loss: 3.5014\n",
      "Epoch 107/200\n",
      "2565/2565 [==============================] - 1028s 401ms/step - loss: 3.4956\n",
      "Epoch 108/200\n",
      "2565/2565 [==============================] - 1028s 401ms/step - loss: 3.4946\n",
      "Epoch 109/200\n",
      "2565/2565 [==============================] - 1028s 401ms/step - loss: 3.4912\n",
      "Epoch 110/200\n",
      "2565/2565 [==============================] - 1028s 401ms/step - loss: 3.4861\n",
      "Epoch 111/200\n",
      "2565/2565 [==============================] - 1028s 401ms/step - loss: 3.4736\n",
      "Epoch 112/200\n",
      "2565/2565 [==============================] - 1040s 405ms/step - loss: 3.4659\n",
      "Epoch 113/200\n",
      "2565/2565 [==============================] - 1038s 405ms/step - loss: 3.4495\n",
      "Epoch 114/200\n",
      "2565/2565 [==============================] - 1056s 412ms/step - loss: 3.4310\n",
      "Epoch 115/200\n",
      "2565/2565 [==============================] - 1047s 408ms/step - loss: 3.4138\n",
      "Epoch 116/200\n",
      "2565/2565 [==============================] - 1051s 410ms/step - loss: 3.4134\n",
      "Epoch 117/200\n",
      "2565/2565 [==============================] - 1039s 405ms/step - loss: 3.4239\n",
      "Epoch 118/200\n",
      "2565/2565 [==============================] - 1035s 403ms/step - loss: 3.4457\n",
      "Epoch 119/200\n",
      "2565/2565 [==============================] - 1049s 409ms/step - loss: 3.4680\n",
      "Epoch 120/200\n",
      "2565/2565 [==============================] - 1055s 411ms/step - loss: 3.4855\n",
      "Epoch 121/200\n",
      "2565/2565 [==============================] - 1074s 419ms/step - loss: 3.4872\n",
      "Epoch 122/200\n",
      "2565/2565 [==============================] - 1089s 425ms/step - loss: 3.4994\n",
      "Epoch 123/200\n",
      "2565/2565 [==============================] - 1091s 425ms/step - loss: 3.4898\n",
      "Epoch 124/200\n",
      "2565/2565 [==============================] - 1094s 426ms/step - loss: 3.4862\n",
      "Epoch 125/200\n",
      "2565/2565 [==============================] - 1087s 424ms/step - loss: 3.4629\n",
      "Epoch 126/200\n",
      "2565/2565 [==============================] - 1088s 424ms/step - loss: 3.4396\n",
      "Epoch 127/200\n",
      "2565/2565 [==============================] - 1080s 421ms/step - loss: 3.4152\n",
      "Epoch 128/200\n",
      "2565/2565 [==============================] - 1064s 415ms/step - loss: 3.3901\n",
      "Epoch 129/200\n",
      "2565/2565 [==============================] - 1078s 420ms/step - loss: 3.3674\n",
      "Epoch 130/200\n",
      "2565/2565 [==============================] - 1062s 414ms/step - loss: 3.3444\n",
      "Epoch 131/200\n",
      "2565/2565 [==============================] - 1091s 425ms/step - loss: 3.3232\n",
      "Epoch 132/200\n",
      "2565/2565 [==============================] - 1090s 425ms/step - loss: 3.3038\n",
      "Epoch 133/200\n",
      "2565/2565 [==============================] - 1089s 425ms/step - loss: 3.2989\n",
      "Epoch 134/200\n",
      "2565/2565 [==============================] - 1079s 421ms/step - loss: 3.2927\n",
      "Epoch 135/200\n",
      "2565/2565 [==============================] - 1085s 423ms/step - loss: 3.2874\n",
      "Epoch 136/200\n",
      "2565/2565 [==============================] - 1083s 422ms/step - loss: 3.3007\n",
      "Epoch 137/200\n",
      "2565/2565 [==============================] - 1069s 417ms/step - loss: 3.3023\n",
      "Epoch 138/200\n",
      "2565/2565 [==============================] - 1069s 417ms/step - loss: 3.2565\n",
      "Epoch 139/200\n",
      "2565/2565 [==============================] - 1067s 416ms/step - loss: 3.2396\n",
      "Epoch 140/200\n",
      "2565/2565 [==============================] - 1059s 413ms/step - loss: 3.2263\n",
      "Epoch 141/200\n",
      "2565/2565 [==============================] - 1082s 422ms/step - loss: 3.2201\n",
      "Epoch 142/200\n",
      "2565/2565 [==============================] - 1086s 423ms/step - loss: 3.2199\n",
      "Epoch 143/200\n",
      "2565/2565 [==============================] - 1085s 423ms/step - loss: 3.2206\n",
      "Epoch 144/200\n",
      "2565/2565 [==============================] - 1087s 424ms/step - loss: 3.2050\n",
      "Epoch 145/200\n",
      "2565/2565 [==============================] - 1087s 424ms/step - loss: 3.2090\n",
      "Epoch 146/200\n",
      "2565/2565 [==============================] - 1083s 422ms/step - loss: 3.2164\n",
      "Epoch 147/200\n",
      "2565/2565 [==============================] - 1056s 412ms/step - loss: 3.2110\n",
      "Epoch 148/200\n",
      "2565/2565 [==============================] - 1071s 418ms/step - loss: 3.2030\n",
      "Epoch 149/200\n",
      "2565/2565 [==============================] - 1059s 413ms/step - loss: 3.1895\n",
      "Epoch 150/200\n",
      "2565/2565 [==============================] - 1032s 402ms/step - loss: 3.1939\n",
      "Epoch 151/200\n",
      "2565/2565 [==============================] - 1038s 405ms/step - loss: 3.1953\n",
      "Epoch 152/200\n",
      "2565/2565 [==============================] - 1045s 408ms/step - loss: 3.2067\n",
      "Epoch 153/200\n",
      "2565/2565 [==============================] - 1045s 407ms/step - loss: 3.2327\n",
      "Epoch 154/200\n",
      "2565/2565 [==============================] - 1058s 412ms/step - loss: 3.2545\n",
      "Epoch 155/200\n",
      "2565/2565 [==============================] - 1046s 408ms/step - loss: 3.2094\n",
      "Epoch 156/200\n",
      "2565/2565 [==============================] - 1029s 401ms/step - loss: 3.1646\n",
      "Epoch 157/200\n",
      "2565/2565 [==============================] - 1029s 401ms/step - loss: 3.1400\n",
      "Epoch 158/200\n",
      "2565/2565 [==============================] - 1028s 401ms/step - loss: 3.1368\n",
      "Epoch 159/200\n",
      "2565/2565 [==============================] - 1028s 401ms/step - loss: 3.1378\n",
      "Epoch 160/200\n",
      "2565/2565 [==============================] - 1027s 400ms/step - loss: 3.1601\n",
      "Epoch 161/200\n",
      "2565/2565 [==============================] - 1025s 399ms/step - loss: 3.1698\n",
      "Epoch 162/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.1867\n",
      "Epoch 163/200\n",
      "2565/2565 [==============================] - 1024s 399ms/step - loss: 3.1832\n",
      "Epoch 164/200\n",
      "2565/2565 [==============================] - 1024s 399ms/step - loss: 3.1833\n",
      "Epoch 165/200\n",
      "2565/2565 [==============================] - 1024s 399ms/step - loss: 3.1804\n",
      "Epoch 166/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.1798\n",
      "Epoch 167/200\n",
      "2565/2565 [==============================] - 1024s 399ms/step - loss: 3.1776\n",
      "Epoch 168/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.1753\n",
      "Epoch 169/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.1600\n",
      "Epoch 170/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.1332\n",
      "Epoch 171/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.1089\n",
      "Epoch 172/200\n",
      "2565/2565 [==============================] - 1024s 399ms/step - loss: 3.0971\n",
      "Epoch 173/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.1108\n",
      "Epoch 174/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.1171\n",
      "Epoch 175/200\n",
      "2565/2565 [==============================] - 1027s 401ms/step - loss: 3.1225\n",
      "Epoch 176/200\n",
      "2565/2565 [==============================] - 1028s 401ms/step - loss: 3.1212\n",
      "Epoch 177/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.1175\n",
      "Epoch 178/200\n",
      "2565/2565 [==============================] - 1027s 400ms/step - loss: 3.1260\n",
      "Epoch 179/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.1338\n",
      "Epoch 180/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.1223\n",
      "Epoch 181/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.1316\n",
      "Epoch 182/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.1676\n",
      "Epoch 183/200\n",
      "2565/2565 [==============================] - 1025s 399ms/step - loss: 3.1837\n",
      "Epoch 184/200\n",
      "2565/2565 [==============================] - 1021s 398ms/step - loss: 3.1124\n",
      "Epoch 185/200\n",
      "2565/2565 [==============================] - 1022s 398ms/step - loss: 3.1054\n",
      "Epoch 186/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.1079\n",
      "Epoch 187/200\n",
      "2565/2565 [==============================] - 1023s 399ms/step - loss: 3.0966\n",
      "Epoch 188/200\n",
      "2565/2565 [==============================] - 1024s 399ms/step - loss: 3.1021\n",
      "Epoch 189/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.1005\n",
      "Epoch 190/200\n",
      "2565/2565 [==============================] - 1024s 399ms/step - loss: 3.1565\n",
      "Epoch 191/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.1791\n",
      "Epoch 192/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.1889\n",
      "Epoch 193/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.2182\n",
      "Epoch 194/200\n",
      "2565/2565 [==============================] - 1027s 401ms/step - loss: 3.2531\n",
      "Epoch 195/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.2788\n",
      "Epoch 196/200\n",
      "2565/2565 [==============================] - 1027s 400ms/step - loss: 3.3025\n",
      "Epoch 197/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.2595\n",
      "Epoch 198/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.2088\n",
      "Epoch 199/200\n",
      "2565/2565 [==============================] - 1027s 400ms/step - loss: 3.2132\n",
      "Epoch 200/200\n",
      "2565/2565 [==============================] - 1026s 400ms/step - loss: 3.2185\n"
     ]
    }
   ],
   "source": [
    "train_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kqv9bYxUOc-I"
   },
   "source": [
    "### `predict.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSh0V6T-OyeG"
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = \"Rest-Duration-weights-improvement-02-4.8267.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8geg-cFOqJ9"
   },
   "outputs": [],
   "source": [
    "def generate():\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    # Get all pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab)\n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uuBMeimZOrjt"
   },
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, pitchnames, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    # map between notes and integers and back\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    sequence_length = 100\n",
    "    network_input = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "\n",
    "    return (network_input, normalized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5inpZR9gOttW"
   },
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    # Load the weights to each node\n",
    "    model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-O-pHEKOw26"
   },
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = numpy.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = numpy.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zdYDwJdMO6w8"
   },
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                try:\n",
    "                    new_note = note.Note(current_note.split('_')[0])\n",
    "                    new_note.storedInstrument = instrument.Piano()\n",
    "                    notes.append(new_note)\n",
    "                except:\n",
    "                    try:\n",
    "                        new_note = note.Note(current_note)\n",
    "                        new_note.storedInstrument = instrument.Piano()\n",
    "                        notes.append(new_note)\n",
    "                    except:\n",
    "                        try:\n",
    "                            new_note = note.Note(int(current_note))\n",
    "                            new_note.storedInstrument = instrument.Piano()\n",
    "                            notes.append(new_note)\n",
    "                        except:\n",
    "                            pass\n",
    "            try:\n",
    "                new_chord = chord.Chord(notes)\n",
    "                new_chord.offset = offset\n",
    "                output_notes.append(new_chord)\n",
    "            except:\n",
    "                pass\n",
    "        # pattern is a rest\n",
    "        elif pattern == \"R\":\n",
    "            # print(\"rest detected\")\n",
    "            new_rest = note.Rest()\n",
    "            # new_rest.duration.quarterLength = 0.5\n",
    "            new_rest.storedInstrument = instrument.Piano()\n",
    "            new_rest.offset = offset\n",
    "            output_notes.append(new_rest)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            # print(pattern)\n",
    "            note_pitch, note_length = pattern.split(\"_\")\n",
    "            # print((note_pitch, note_length))\n",
    "            try:\n",
    "                new_note = note.Note(note_pitch)\n",
    "                try:\n",
    "                    new_note.duration = duration.Duration(float(note_length))\n",
    "                    new_note.storedInstrument = instrument.Piano()\n",
    "                    new_note.offset = offset\n",
    "                    output_notes.append(new_note)\n",
    "                except:\n",
    "                    new_note.storedInstrument = instrument.Piano()\n",
    "                    new_note.offset = offset\n",
    "                    output_notes.append(new_note)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output_new_durations.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1cOXpVrO-3f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPdZYyhMPBdX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
